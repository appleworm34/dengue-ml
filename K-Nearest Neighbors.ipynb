{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b776b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = pd.read_csv(\"cleaned_data.csv\", index_col = 0)\n",
    "cases = pd.read_csv(\"cases.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4c0aa",
   "metadata": {},
   "source": [
    "###K-Nearest Neighbours\n",
    "The k-nearest neighbors (KNN) algorithm is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaling data\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X = sc_X.fit_transform(cleaned_data)\n",
    "y = sc_y.fit_transform(cases)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "# check the sample sizes\n",
    "print(\"Train Set :\", X_train.shape, y_train.shape)\n",
    "print(\"Test Set  :\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7922117",
   "metadata": {},
   "source": [
    "Using KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_model = KNeighborsRegressor(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "cv = KFold(n_splits = 10, random_state = 1, shuffle = True)\n",
    "\n",
    "scores = cross_val_score(knn_model, X_train, y_train.ravel(), scoring='neg_mean_squared_error', cv=cv, n_jobs=1)\n",
    "\n",
    "print(\"Mean of MSE = \", np.mean(scores)*-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571ef610",
   "metadata": {},
   "source": [
    "We then tune and optimize KNN by finding the best performing value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd224287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\"n_neighbors\": range(1, 50)}\n",
    "gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)\n",
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b511fdbd",
   "metadata": {},
   "source": [
    "Best performing value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2aaafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b39c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = cross_val_score(gridsearch, X_train, y_train.ravel(), scoring='neg_mean_squared_error', cv=cv, n_jobs=1)\n",
    "\n",
    "print(\"Mean of MSE = \", np.mean(scores1)*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a5f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "\"n_neighbors\": range(1, 50),\n",
    "\"weights\": [\"uniform\", \"distance\"],\n",
    "}\n",
    "w_gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)\n",
    "w_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904531d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1200a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = cross_val_score(w_gridsearch, X_train, y_train.ravel(), scoring='neg_mean_squared_error', cv=cv, n_jobs=1)\n",
    "\n",
    "print(\"Mean of MSE = \", np.mean(scores2)*-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69470e5a",
   "metadata": {},
   "source": [
    "Further Improving on kNN in scikit-learn With Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be4409",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = w_gridsearch.best_params_[\"n_neighbors\"]\n",
    "best_weights = w_gridsearch.best_params_[\"weights\"]\n",
    "bagged_knn = KNeighborsRegressor(n_neighbors=best_k, weights=best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagging_model = BaggingRegressor(bagged_knn, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ce923",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores3 = cross_val_score(bagging_model, X_train, y_train.ravel(), scoring='neg_mean_squared_error', cv=cv, n_jobs=1)\n",
    "\n",
    "print(\"Mean of MSE = \", np.mean(scores3)*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94544a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparison of MSE of the Four Models:\")\n",
    "\n",
    "print(\"Arbitrary k: \", np.mean(scores)*-1)\n",
    "\n",
    "print(\"GridSearchCV for k: \", np.mean(scores1)*-1)\n",
    "\n",
    "print(\"GridSearchCV for k and weights: \", np.mean(scores2)*-1)\n",
    "\n",
    "print(\"Bagging and GridSearchCV: \", np.mean(scores3)*-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcbda40",
   "metadata": {},
   "source": [
    "We use kNN with bagging to predict the total cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f954b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_model.fit(X_train, y_train.ravel())\n",
    "test_preds_grid = bagging_model.predict(X_test)\n",
    "cases_pred = sc_y.inverse_transform(test_preds_grid.reshape(-1,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0909d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = sc_y.inverse_transform(y_test)\n",
    "df1 = pd.DataFrame(y_test, columns = ['total_cases'])\n",
    "\n",
    "# rounding up to nearest whole no.\n",
    "cases_pred = np.rint(cases_pred)\n",
    "\n",
    "df = pd.DataFrame(cases_pred, columns = ['pred_total_cases'])\n",
    "\n",
    "# combining total cases test and the predicted total cases into a dataframe\n",
    "all_data = pd.concat([df1, df], axis = 1)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb781c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE of model on test data: \", metrics.mean_absolute_error(y_test, cases_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
